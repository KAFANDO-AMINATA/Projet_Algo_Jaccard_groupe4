{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import string\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "import nltk\n",
        "\n",
        "# Téléchargement les ressources NLTK \n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence, remove_stopwords=True, use_lemmatization=True):\n",
        "    \"\"\"\n",
        "    Prétraitement d'une phrase :\n",
        "    - minuscules\n",
        "    - suppression ponctuation\n",
        "    - stopwords\n",
        "    - lemmatisation\n",
        "    \"\"\"\n",
        "    if not sentence:\n",
        "        return []\n",
        "\n",
        "    # Minuscules + suppression ponctuation\n",
        "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
        "    sentence = sentence.lower().translate(translator)\n",
        "\n",
        "    # Tokenisation\n",
        "    words = sentence.split()\n",
        "\n",
        "    # Stopwords \n",
        "    if remove_stopwords:\n",
        "        stop_words = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if w not in stop_words]\n",
        "\n",
        "    # Lemmatisation\n",
        "    if use_lemmatization:\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        words = [lemmatizer.lemmatize(w) for w in words]\n",
        "\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'happy', 'felicitousness', 'felicity', 'happiness'}\n"
          ]
        }
      ],
      "source": [
        "def get_related_forms(word):\n",
        "    forms = set([word])\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            for deriv in lemma.derivationally_related_forms():\n",
        "                forms.add(deriv.name())\n",
        "    return forms\n",
        "\n",
        "print(get_related_forms(\"happy\"))  # {'happy', 'happiness'}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def are_synonyms(word1, word2):\n",
        "    \"\"\"\n",
        "    Vérifie si deux mots sont synonymes avec WordNet\n",
        "    \"\"\"\n",
        "    if word1 == word2:\n",
        "        return True\n",
        "\n",
        "    synsets1 = wordnet.synsets(word1)\n",
        "    synsets2 = wordnet.synsets(word2)\n",
        "\n",
        "    if not synsets1 or not synsets2:\n",
        "        return False\n",
        "\n",
        "    for syn1 in synsets1:\n",
        "        for syn2 in synsets2:\n",
        "            # Même synset → mots synonymes\n",
        "            if syn1 == syn2:\n",
        "                return True\n",
        "    return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def are_related(w1, w2):\n",
        "    \"\"\"\n",
        "    Vérifie si deux mots sont identiques, synonymes ou formes dérivées.\n",
        "    \"\"\"\n",
        "    # Même mot\n",
        "    if w1 == w2:\n",
        "        return True\n",
        "\n",
        "    # Vérifie s’ils sont synonymes\n",
        "    for syn1 in wordnet.synsets(w1):\n",
        "        for lemma in syn1.lemmas():\n",
        "            if lemma.name() == w2:\n",
        "                return True\n",
        "\n",
        "    # Vérifie s’ils partagent une forme dérivée\n",
        "    related_w1 = get_related_forms(w1)\n",
        "    related_w2 = get_related_forms(w2)\n",
        "    if related_w1 & related_w2:  # intersection non vide\n",
        "        return True\n",
        "\n",
        "    return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def jaccard_similarity_sentences(sentence1, sentence2, remove_stopwords=True, use_lemmatization=True):\n",
        "    \"\"\"\n",
        "    Calcule la similarité de Jaccard entre deux phrases \n",
        "    en tenant compte :\n",
        "    - des synonymes\n",
        "    - des formes dérivées (happy ↔ happiness)\n",
        "    - des répétitions (Counter)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Prétraitement (à adapter selon ta fonction preprocess_sentence)\n",
        "        words1 = preprocess_sentence(sentence1, remove_stopwords, use_lemmatization)\n",
        "        words2 = preprocess_sentence(sentence2, remove_stopwords, use_lemmatization)\n",
        "\n",
        "        if not words1 or not words2:\n",
        "            return 0.0\n",
        "\n",
        "        counter1 = Counter(words1)\n",
        "        counter2 = Counter(words2)\n",
        "\n",
        "        intersection_count = 0\n",
        "        used_pairs = set()\n",
        "\n",
        "        for w1 in counter1:\n",
        "            for w2 in counter2:\n",
        "                if are_related(w1, w2) and (w1, w2) not in used_pairs:\n",
        "                    intersection_count += min(counter1[w1], counter2[w2])\n",
        "                    used_pairs.add((w1, w2))\n",
        "                    break\n",
        "\n",
        "        union_count = sum(counter1.values()) + sum(counter2.values()) - intersection_count\n",
        "        return intersection_count / union_count if union_count else 0.0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur lors du calcul : {e}\")\n",
        "        return 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===  Calculateur de similarité de phrases (Jaccard) ===\n",
            "Saisissez deux phrases pour comparer leur similarité.\n",
            "Tapez 'q' à tout moment pour quitter.\n",
            "\n",
            "\n",
            " Similarité Jaccard = 1.00 (entre 0 et 1)\n",
            "\n",
            "\n",
            " Merci d'avoir utilisé le calculateur ! \n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    print(\"===  Calculateur de similarité de phrases (Jaccard) ===\")\n",
        "    print(\"Saisissez deux phrases pour comparer leur similarité.\")\n",
        "    print(\"Tapez 'q' à tout moment pour quitter.\\n\")\n",
        "\n",
        "    while True:\n",
        "        # Saisie utilisateur\n",
        "        s1 = input(\" Entrez la première phrase : \")\n",
        "        if s1.lower() == \"q\":\n",
        "            break\n",
        "\n",
        "        s2 = input(\" Entrez la deuxième phrase : \")\n",
        "        if s2.lower() == \"q\":\n",
        "            break\n",
        "\n",
        "        # Calcul et affichage du résultat\n",
        "        score = jaccard_similarity_sentences(s1, s2)\n",
        "        print(f\"\\n Similarité Jaccard = {score:.2f} (entre 0 et 1)\\n\")\n",
        "\n",
        "        # Demander si l'utilisateur veut continuer\n",
        "        again = input(\"Voulez-vous comparer d'autres phrases ? (o/n) : \").strip().lower()\n",
        "        if again != \"o\":\n",
        "            break\n",
        "\n",
        "    print(\"\\n Merci d'avoir utilisé le calculateur ! \")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
